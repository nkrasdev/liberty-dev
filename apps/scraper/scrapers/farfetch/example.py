import asyncio

from services.scraper_core import get_logger, save_products
from services.scrapers.farfetch.config import FarfetchConfig
from services.scrapers.farfetch.scraper import FarfetchScraper

logger = get_logger(__name__)


async def main():
    """–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä —Å–∫—Ä–∞–ø–∏–Ω–≥–∞."""

    test_urls = [
        "https://www.farfetch.com/shopping/men/nike-air-force-1-supreme-item-15252505.aspx",
        "https://www.farfetch.com/shopping/women/nike-air-force-1-low-mini-box-logo-black-supreme-item-15252506.aspx",
        "https://www.farfetch.com/shopping/women/nike-dunk-low-retro-item-16403569.aspx",
    ]

    config = FarfetchConfig(
        target_brands=["Nike", "Adidas", "Supreme"],
        use_mobile_ua=True,
        visit_intermediate_pages=False,
        randomize_delays=True,
        timeout=60,
        max_retries=3,
        retry_delay=2.0,
        min_delay=1.0,
        max_delay=3.0,
        proxy_list=[
            "http://af1BPm:TwRpF9@168.80.203.44:8000",
            "socks5://af1BPm:TwRpF9@168.80.203.44:8000",
            "socks4://af1BPm:TwRpF9@168.80.203.44:8000",
        ],
    )

    scraper = FarfetchScraper(config)

    try:
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤...")

        products = await scraper.scrape_products(test_urls)

        for i, product in enumerate(products, 1):
            logger.info(f"–¢–æ–≤–∞—Ä {i}: {product.name}")
            logger.info(f"–ë—Ä–µ–Ω–¥: {product.brand}")
            logger.info(f"–¶–≤–µ—Ç: {product.color}")
            logger.info(f"–í–∞—Ä–∏–∞–Ω—Ç–æ–≤: {len(product.variants)}")

            min_price, max_price = product.price_range
            if min_price and max_price:
                logger.info(f"   –¶–µ–Ω—ã: ${min_price:.0f} - ${max_price:.0f}")

        save_products(products, "scraped_products.json")

        logger.info("üéâ –°–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        logger.info(f"üìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")

    except KeyboardInterrupt:
        logger.info("‚ö†Ô∏è –°–∫—Ä–∞–ø–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫—Ä–∞–ø–∏–Ω–≥–µ: {e}")
    finally:
        await scraper.close()


if __name__ == "__main__":
    asyncio.run(main())
